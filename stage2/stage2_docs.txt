After the training data is acquired and preprocessed, it has to be transformed into a Markov chain model. 
The first step is to map the connections between tokens in the corpus. 
For this, we are going to use bigrams.

1. Transform the corpus into a collection of bigrams. 
   The results should contain all the possible bigrams from the corpus, which means that:
      — Every token from the corpus should be a head of a bigram with the exception of the last token which cannot become a head since nothing follows it;
      — Every token from the corpus should be a tail of a bigram with the exception of the first token which cannot possibly be the tail of a bigram because nothing precedes it.
2. Output the number of all bigrams in the corpus.
3. Take an integer as user input and print the bigrams with the corresponding index. 
    Repeat this process until the string exit is input. 
    Also, making sure that the input is actually an integer that falls in the range of the collection of bigrams. 
    If that is not the case, print an error message and request a new input. Error messages should contain the types of errors (Type Error, Index Error, etc.). 
    Each bigram should have the format Head: [head] Tail: [tail] and should be printed in a new line.